{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb5723c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 11:22:01,387 [585] WARNING  py.warnings:109: [JupyterRequire] /opt/conda/lib/python3.8/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584edba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import igraph as ig\n",
    "import cairocffi\n",
    "#import pycairo\n",
    "import hypernetx as hnx\n",
    "import hypernetx.algorithms.generative_models as gm\n",
    "import hypernetx.algorithms.hypergraph_modularity as hmod\n",
    "import hnxwidget as hnxw\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from hypernetx import Hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0b23f2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-913149d8fef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(numpy.linspace(10,10,10), numpy.linspace(10,10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df68454",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = randint(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "m = 20 \n",
    "\n",
    "Gr = nx.generators.erdos_renyi_graph(20, 0.2)\n",
    "nx.draw(Gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b8c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 25\n",
    "k1 = {i : random.randint(1, 25) for i in range(n)}\n",
    "k2 = {i : sorted(k1.values())[i] for i in range(n)}\n",
    "H_chung = gm.chung_lu_hypergraph(k1, k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90548f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "hnx.drawing.rubber_band.draw(H_chung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc46ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 25\n",
    "m = n\n",
    "p = 0.1\n",
    "H = gm.erdos_renyi_hypergraph(n, m, p)\n",
    "\n",
    "hnx.drawing.rubber_band.draw(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7691f606",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'H' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8f242c236703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwo_section\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#hnx.drawing.two_column.draw_hyper_edges(H, [0,1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'H' is not defined"
     ]
    }
   ],
   "source": [
    "G = hmod.two_section(H)\n",
    "ig.plot(G)\n",
    "#hnx.drawing.two_column.draw_hyper_edges(H, [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hnx.drawing.two_column.layout_two_column(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d674f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hnx.reports.descriptive_stats.degree_dist(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52978c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "hnx.reports.descriptive_stats.edge_size_dist(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(hnx.reports.descriptive_stats.edge_size_dist(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f620d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "HG = hmod.precompute_attributes(H)\n",
    "HG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563f420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d507a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcsbm_hypergraph(k1, k2, g1, g2, omega):\n",
    "    \"\"\"\n",
    "    A function to generate an extension of DCSBM hypergraph as implemented by Mirah Shi and described for\n",
    "    bipartite networks by Larremore et al. in https://doi.org/10.1103/PhysRevE.90.012805\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k1 : dictionary\n",
    "        This a dictionary where the keys are node ids and the values are node degrees.\n",
    "    k2 : dictionary\n",
    "        This a dictionary where the keys are edge ids and the values are edge degrees also known as edge sizes.\n",
    "    g1 : dictionary\n",
    "        This a dictionary where the keys are node ids and the values are the group ids to which the node belongs.\n",
    "        The keys must match the keys of k1.\n",
    "    g2 : dictionary\n",
    "        This a dictionary where the keys are edge ids and the values are the group ids to which the edge belongs.\n",
    "        The keys must match the keys of k2.\n",
    "    omega : 2D numpy array\n",
    "        This is a matrix with entries which specify the number of edges between a given node community and edge community.\n",
    "        The number of rows must match the number of node communities and the number of columns\n",
    "        must match the number of edge communities.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    HyperNetX Hypergraph object\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The sums of k1 and k2 should be the same. If they are not the same, this function returns a warning but still runs.\n",
    "    The sum of k1 (and k2) and omega should be the same. If they are not the same, this function returns a warning\n",
    "    but still runs and the number of entries in the incidence matrix is determined by the omega matrix.\n",
    "\n",
    "    The output currently is a static Hypergraph object. Dynamic hypergraphs are not currently supported.\n",
    "\n",
    "    Example::\n",
    "\n",
    "    >>> n = 100\n",
    "    >>> k1 = {i : random.randint(1, 100) for i in range(n)}\n",
    "    >>> k2 = {i : sorted(k1.values())[i] for i in range(n)}\n",
    "    >>> g1 = {i : random.choice([0, 1]) for i in range(n)}\n",
    "    >>> g2 = {i : random.choice([0, 1]) for i in range(n)}\n",
    "    >>> omega = np.array([[100, 10], [10, 100]])\n",
    "    >>> H = gm.dcsbm_hypergraph(k1, k2, g1, g2, omega)\n",
    "    \"\"\"\n",
    "\n",
    "    # sort dictionary by degree in decreasing order\n",
    "    Nlabels = [n for n, _ in sorted(k1.items(), key=lambda d: d[1], reverse=True)]\n",
    "    Mlabels = [m for m, _ in sorted(k2.items(), key=lambda d: d[1], reverse=True)]\n",
    "\n",
    "    # these checks verify that the sum of node and edge degrees and the sum of node degrees\n",
    "    # and the sum of community connection matrix differ by less than a single edge.\n",
    "    if abs(sum(k1.values()) - sum(k2.values())) > 1:\n",
    "        warnings.warn(\n",
    "            \"The sum of the degree sequence does not match the sum of the size sequence\"\n",
    "        )\n",
    "\n",
    "    if abs(sum(k1.values()) - np.sum(omega)) > 1:\n",
    "        warnings.warn(\n",
    "            \"The sum of the degree sequence does not match the entries in the omega matrix\"\n",
    "        )\n",
    "\n",
    "    # get indices for each community\n",
    "    community1Indices = defaultdict(list)\n",
    "    for label in Nlabels:\n",
    "        group = g1[label]\n",
    "        community1Indices[group].append(label)\n",
    "\n",
    "    community2Indices = defaultdict(list)\n",
    "    for label in Mlabels:\n",
    "        group = g2[label]\n",
    "        community2Indices[group].append(label)\n",
    "\n",
    "    bipartite_edges = list()\n",
    "\n",
    "    kappa1 = defaultdict(lambda: 0)\n",
    "    kappa2 = defaultdict(lambda: 0)\n",
    "    for id, g in g1.items():\n",
    "        kappa1[g] += k1[id]\n",
    "    for id, g in g2.items():\n",
    "        kappa2[g] += k2[id]\n",
    "\n",
    "    for group1 in community1Indices.keys():\n",
    "        for group2 in community2Indices.keys():\n",
    "            # for each constant probability patch\n",
    "            try:\n",
    "                groupConstant = omega[group1, group2] / (\n",
    "                    kappa1[group1] * kappa2[group2]\n",
    "                )\n",
    "            except:\n",
    "                groupConstant = 0\n",
    "\n",
    "            for u in community1Indices[group1]:\n",
    "                j = 0\n",
    "                v = community2Indices[group2][j]  # start from beginning every time\n",
    "                # max probability\n",
    "                p = min(k1[u] * k2[v] * groupConstant, 1)\n",
    "                while j < len(community2Indices[group2]):\n",
    "                    if p != 1:\n",
    "                        r = random.random()\n",
    "                        try:\n",
    "                            j = j + math.floor(math.log(r) / math.log(1 - p))\n",
    "                        except:\n",
    "                            j = np.inf\n",
    "                    if j < len(community2Indices[group2]):\n",
    "                        v = community2Indices[group2][j]\n",
    "                        q = min((k1[u] * k2[v]) * groupConstant, 1)\n",
    "                        r = random.random()\n",
    "                        if r < q / p:\n",
    "                            # no duplicates\n",
    "                            bipartite_edges.append((v, u))\n",
    "\n",
    "                            p = q\n",
    "                            j = j + 1\n",
    "\n",
    "    df = pd.DataFrame(bipartite_edges)\n",
    "    return Hypergraph(df, static=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b5c7c",
   "metadata": {},
   "source": [
    "## The output currently is a static Hypergraph object. Dynamic hypergraphs are not currently supported.\n",
    "\n",
    "### Set is faster and almost all the graphers are working with sets.\n",
    "\n",
    "### The order of edges does not count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1a9960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60435f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(string.ascii_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0bbd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.set_index('Number')['Data'].to_dict()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1803364",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_file = \n",
    "\n",
    "with open(contract_file, 'r', encoding='UTF-8') as f:\n",
    "        f = f.read()\n",
    "        dfco = json.loads(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ce8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb0ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7efab9bb",
   "metadata": {},
   "source": [
    "# Clustering dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fca410",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD_groups = {}\n",
    "clique_groups = {}\n",
    "\n",
    "for i in range(1, len(assign)+1):\n",
    "    ABCD_groups[i] = [int(assign[i-1])]\n",
    "    clique_groups[i] = []\n",
    "    \n",
    "ABCD_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_t,weights_t = zip(*nx.get_edge_attributes(graphs['graph_1'],'weight').items())\n",
    "len(weights_t)\n",
    "nx.draw(graphs['graph_1'], pos = nx.kamada_kawai_layout(G2) ,with_labels=True, edgelist=edges_t, width=weights_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7344bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[dict(zip(val, col)) for val, col in zip(*groups_k['w_1.0'].values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcddfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(x for x in range(1,max(nodelist)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc48e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict((v, [k]) for k in groups_k['w_1.0'] for v in groups_k['w_1.0'][k]).keys())\n",
    "sorted(nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a30da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_k['w_1.0']\n",
    "fasz = {1: [1, 2], 2:[2, 3]}\n",
    "fasz\n",
    "akarmi = {}\n",
    "for k in fasz:\n",
    "    for v in fasz[k]:\n",
    "        akarmi.setdefault(v, []).append(k)\n",
    "#dict((dict.setdefault(v, []).append(k)) for k in fasz for v in fasz[k])\n",
    "akarmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "akarmi = dict((v, [k]) for k in groups_k['w_1.0'] for v in groups_k['w_1.0'][k])\n",
    "akarmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bd199",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in sorted(nodelist) if x not in (list(dict((v, [k]) for k in groups_k['w_1.0'] for v in groups_k['w_1.0'][k]).keys()))]"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1674163220672,
   "trusted": false
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
